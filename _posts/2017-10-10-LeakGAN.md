---
layout: post
title: LeakGAN
---

## LeakGAN

[1] Jiaxian Guo, Sidi Lu, Han Cai, Weinan Zhang, Yong Yu, Jun Wang. "Long Text Generation via Adversarial Training with Leaked Information"[https://arxiv.org/pdf/1709.08624.pdf](https://arxiv.org/pdf/1709.08624.pdf)

通过增强学习中的policy gradient用GAN来进行文本生成可以生成不错的效果，但是呢，scalar作用比较有限:
* 只有当文本全部生成之后
* 缺乏中间信息
所以这会限制生成的文本的长度。

这篇文章退出了LeakGAN，允许D去泄露一些内部高层的信息给G。G-MANAGER会利用这些信息生成latend vector，从而指导G-WORKER去生成下一个单词。

#### Introduction

log-likehood->exposure，scheduled sampling approach->inconsistant，GAN->generate images

GAN->generate text->长度受限，难以训练，主要问题：
* D的反馈是稀疏的，只有当整个句子生成之后才能得到反馈
* D是一个二分类器，只能反馈给G一个scalar，并且是不可导的，不能够把一些中间信息透露出来

一方面，除了最终的反馈之外，D可以提供一些额外的指导，因为毕竟D是一个可训练的网络如CNN，不是一个黑盒子。

